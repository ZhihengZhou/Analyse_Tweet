col[1]
col[2]
newrt[,s] = col
rt[[s]]
newrt[,'hashtags'] = unlist(col)
col <- sapply(rt[['hashtags']], function(x){
return(merge(x, " "))
})
col
newrt[,'hashtags'] = col
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]])){
newrt[,col_name] = rt[,col_name]
}
else{
column <- sapply(rt[[col_name]], function(x){
return(merge(x, " "))
})
newrt[,col_name] = column
}
}
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
merge <- function(string_list, sep){
if(length(string_list) <= 1){
return(string_list)
}
merged_string = string_list[1]
for(i in 2:length(string_list)){
merged_string = paste(merged_string, string_list[i], sep = sep)
}
return(merged_string)
}
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
write.csv(newrt, file = "./test.csv", row.names = TRUE)
read_df <- read.csv("./test.csv")
View(read_df)
rt$created_at[1]
start_time = Sys.time()
start_time
start_time > rt$created_at[1]
# Search tweets
rt <- search_tweets(
"#QandA", n = 1500, include_rts = FALSE
)
nrow(rt)
rt[1,]
inDuration = which(rt$created_at >= start_time)
inDuration
# Search tweets
rt = search_tweets(
"#QandA", n = 1500, include_rts = FALSE
)
inDuration = which(rt$created_at >= start_time)
inDuration
inDuration = which(rt$created_at >= now_time)
start_time
start_time - 1
start_time - 3000
start_time - 30000
inDuration = which(rt$created_at >= (now_time-30000))
inDuration = which(rt$created_at >= (start_time-30000))
inDuration
nrow(rt)
length(inDuration)
rt = rt[inDuration,]
nrow(rt)
# Search tweets
rt = search_tweets(
query, n = 1500, include_rts = FALSE
)
query = "#QandA"
inDuration = which(rt$created_at >= (start_time))
rt = rt[inDuration,]
# Search tweets
rt = search_tweets(
query, n = 1500, include_rts = FALSE
)
nrow(rt)
inDuration = which(rt$created_at >= (start_time))
inDuration
newrt <- data.frame(union(data.frame(rt), rt))
newrt <- data.frame(union(rt, rt))
nrow(rt)
newrt <- data.frame(union(rt, rt))
inDuration = which(rt$created_at >= (start_time))
tweet_df = rt[inDuration,]
nrow(tweet_df)
# Search tweets
rt = search_tweets(
query, n = 1500, include_rts = FALSE
)
newrt <- data.frame(union(rt, rt))
newrt <- data.frame(union(data.frame(rt), data.frame(rt)))
union(rt, rt
)
union(rt, rt)
data.frame(union(rt, rt))
merge_string_list <- function(string_list, sep){
if(length(string_list) <= 1){
return(string_list)
}
merged_string = string_list[1]
for(i in 2:length(string_list)){
merged_string = paste(merged_string, string_list[i], sep = sep)
}
return(merged_string)
}
merge(rt, rt)
newrt <- merge(rt, rt)
typeof(rt)
str(rt)
newrt <- merge(rt, rt)
nrow(rt)
nrow(newrt)
ncol(rt)
ncol(newrt)
rt1 <- search_tweets(
"#auspol", n = 100, include_rts = FALSE
)
newrt <- merge(rt, rt1)
ncol(newrt)
nrow(newrt)
newrt <- merge(rt, rt1, all = TRUE)
nrow(newrt)
newrt <- merge(tweet_dt, rt1, all = TRUE)
tweet_df = rt[inDuration,]
nrow(tweet_df)
newrt <- merge(tweet_dt, rt1, all = TRUE)
newrt <- merge(tweet_df, rt1, all = TRUE)
nrow(newdf)
nrow(newrt)
# Search tweets
rt = search_tweets(
query, n = 1500, include_rts = FALSE
)
nrow(rt)
query
inDuration = which(rt$created_at >= (start_time))
inDuration
rt = rt[inDuration,]
nrow(rt)
newrt <- merge(data.frame(tweet_df), rt1, all = TRUE)
newrt
newrt <- merge(data.frame(tweet_df), rt, all = TRUE)
newrt <- merge(data.frame(tweet_df), rt)
nrow(newrt)
newrt <- merge(data.frame(tweet_df), rt, all = TRUE)
newrt <- merge(data.frame(tweet_df), rt1, all = TRUE)
newrt <- merge(data.frame(tweet_df), rt, all = TRUE)
newrt <- rbind(data.frame(tweet_df), rt, all = TRUE)
newrt <- rbind(data.frame(tweet_df), rt)
nrow(newrt)
nrow(rt)
unique(newrt)
nrow(unique(newrt))
nrow(newrt)
nrow(rt)
nrow(tweet_df)
View(tweet_df)
start_time
rt$created_at[1]
rt$created_at[2]
rt$created_at[3]
rt$created_at[4]
search_amount_once = 1500
nrow(tweet_df)
nrow(newrt)
auto_search_tweet <- function(query, search_amount_once, search_step, total_duration){
# Get script start time.
start_time = Sys.time()
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
# Select tweet created during the show.
inDuration = which(rt$created_at >= (start_time))
tweet_df = rt[inDuration,]
previous_tweet_amount = nrow(tweet_df)
while (TRUE) {
# Search tweets
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
inDuration = which(rt$created_at >= (start_time))
rt = rt[inDuration,]
# Combine two tweet data frame
tweet_df = rbind(tweet_df, rt)
raw_rows = nrow(tweet_df)
tweet_df = unique(tweet_df)
unique_rows = nrow(tweet_df)
# No new tweets found, increase the search step.
if(unique_rows - previous_tweet_amount <= 0){
search_step = search_step * 2
}
# Searched tweets are all new, decrease the search step.
if(unique_rows - previous_tweet_amount >= search_amount_once){
search_step = search_step / 2
}
previous_tweet_amount = unique_rows
print(previous_tweet_amount)
print(search_step)
now_time = Sys.time()
if(now_time - start_time > total_duration){
# Save csv
save_df(tweet_df, "test.csv")
break
}
Sys.sleep(search_step)
}
}
auto_search_tweet("#QandA", 500, 3, 300)
auto_search_tweet("#auspol", 500, 3, 300)
auto_search_tweet("#auspol", 500, 3, 5)
save_df <- function(rt, save_name){
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge_string_list(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
write.csv(newrt, file = save_name, row.names = TRUE)
}
auto_search_tweet("#auspol", 500, 3, 5)
auto_search_tweet("#auspol", 5, 3, 30)
auto_search_tweet("#auspol", 2, 3, 30)
auto_search_tweet("#auspol", 2, 3, 30)
auto_search_tweet("#auspol", 2, 10, 30)
auto_search_tweet <- function(query, search_amount_once, search_step, total_duration){
# Get script start time.
start_time = Sys.time()
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
# Select tweet created during the show.
inDuration = which(rt$created_at >= (start_time))
tweet_df = rt[inDuration,]
previous_tweet_amount = nrow(tweet_df)
Sys.sleep(search_step)
while (TRUE) {
# Search tweets
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
inDuration = which(rt$created_at >= (start_time))
rt = rt[inDuration,]
# Combine two tweet data frame
tweet_df = rbind(tweet_df, rt)
raw_rows = nrow(tweet_df)
tweet_df = unique(tweet_df)
unique_rows = nrow(tweet_df)
# No new tweets found, increase the search step.
if(unique_rows - previous_tweet_amount <= 0){
search_step = search_step * 2
}
# Searched tweets are all new, decrease the search step.
if(unique_rows - previous_tweet_amount >= search_amount_once){
search_step = search_step / 2
}
previous_tweet_amount = unique_rows
print(previous_tweet_amount)
print(search_step)
now_time = Sys.time()
if(now_time - start_time > total_duration){
# Save csv
save_df(tweet_df, "test.csv")
break
}
Sys.sleep(search_step)
}
}
auto_search_tweet("#auspol", 2, 10, 30)
auto_search_tweet("#auspol", 2, 3, 30)
auto_search_tweet("#aus", 2, 3, 30)
auto_search_tweet("a", 2, 3, 30)
token <- create_token(
app = "my_twitter_research_app",
consumer_key = "G3MQONk4InSpaEbLEEii83NeR",
consumer_secret = "sjhQId8edr4nSkccyDiwJwogA6vqHoGDkqGSnTXNCnlQ8kpvkM",
access_token = "875178186383835137-iVunpJKrBqGdP9o59zICU20wzU4mwyD",
access_secret = "ypOqFVOYtuwbXQZ9875iKUAZ7ijtRATFPbnZ6GgnC7MhL")
auto_search_tweet("a", 2, 3, 30)
create_token(
app = "my_twitter_research_app",
consumer_key = "XYznzPFO FZR2a39FwWKN1Jp41",
consumer_secret = "CtkGEWmSevZqJuKl6HHrBxbCybxI1xGLqrD5ynPd9jG0SoHZbD",
access_token = "9551451262-wK2EmA942kxZYIwa5LMKZoQA4Xc2uyIiEwu2YXL",
access_secret = "9vpiSGKg1fIPQtxc5d5ESiFlZQpfbknEN1f1m2xe5byw7")
auto_search_tweet("a", 2, 3, 30)
read_df <- read.csv("./test.csv")
read_df <- read.csv("./test.csv")
View(read_df)
write.csv(tweet_df, file = "./test.csv", row.names = F, col.names=T)
write.csv(tweet_df, file = "./test.csv", row.names = F, col.names=T)
# Save csv
save_df(tweet_df, "test.csv")
auto_search_tweet("a", 2, 3, 30)
save_df <- function(rt, save_name){
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge_string_list(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
write.csv(newrt, file = save_name, row.names = F, col.names=T)
}
read_df <- read.csv("./test.csv")
merge_string_list <- function(string_list, sep){
if(length(string_list) <= 1){
return(string_list)
}
merged_string = string_list[1]
for(i in 2:length(string_list)){
merged_string = paste(merged_string, string_list[i], sep = sep)
}
return(merged_string)
}
save_df <- function(rt, save_name){
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge_string_list(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
write.csv(newrt, file = save_name, row.names = F, col.names=T)
}
auto_search_tweet <- function(query, search_amount_once, search_step, total_duration){
# Get script start time.
start_time = Sys.time()
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
# Select tweet created during the show.
inDuration = which(rt$created_at >= (start_time))
tweet_df = rt[inDuration,]
previous_tweet_amount = nrow(tweet_df)
Sys.sleep(search_step)
while (TRUE) {
# Search tweets
rt = search_tweets(
query, n = search_amount_once, include_rts = FALSE
)
inDuration = which(rt$created_at >= (start_time))
rt = rt[inDuration,]
# Combine two tweet data frame
tweet_df = rbind(tweet_df, rt)
raw_rows = nrow(tweet_df)
tweet_df = unique(tweet_df)
unique_rows = nrow(tweet_df)
# No new tweets found, increase the search step.
if(unique_rows - previous_tweet_amount <= 0){
search_step = search_step * 2
}
# Searched tweets are all new, decrease the search step.
if(unique_rows - previous_tweet_amount >= search_amount_once){
search_step = search_step / 2
}
previous_tweet_amount = unique_rows
print(previous_tweet_amount)
print(search_step)
now_time = Sys.time()
if(now_time - start_time > total_duration){
# Save csv
save_df(tweet_df, "test.csv")
break
}
Sys.sleep(search_step)
}
}
auto_search_tweet("a", 2, 3, 30)
read_df <- read.csv("./test.csv")
save_df <- function(rt, save_name){
newrt = data.frame(rt['user_id'])
for(col_name in colnames(rt)){
if(typeof(rt[[col_name]]) == "list"){
column <- sapply(rt[[col_name]], function(x){
return(merge_string_list(x, " "))
})
newrt[,col_name] = column
}
else{
newrt[,col_name] = rt[,col_name]
}
}
write.csv(newrt, file = save_name, row.names = F)
}
auto_search_tweet("a", 2, 3, 30)
read_df <- read.csv("./test.csv")
View(tweet_df)
View(read_df)
source("/path/to/file/my_fn_lib1.r")
setwd("~/Desktop/Work/search_tweets_during_shows")
source("../Auto_Search_Base.R")
source("../Auto_Search_Base.R")
source("../Auto_Search_Base.R")
setwd("~/Desktop/Work")
setwd("~/Desktop/Work")
setwd("~/Desktop/Work/Src")
start_time
now_time = Sys.time()
now_time
now_time - start_time
# auto_search_tweet("a", 2, 3, 30)
lag = now_time - start_time
now_time - start_time
lag
lag>3000
lag>2
lag>1
typeof(lag)
t = now_time + 30
t
now_time
t - now_time > 10
t = now_time + 5400
t - now_time > 10
t - now_time
t - now_time > 1
t - now_time > 1.5
t - now_time >= 1.5
z <- as.difftime(90, units = "mins")
z
t - now_time >= z
t - start_time
t - start_time > z
View(auto_search_tweet)
View(tweet_df)
View(rt)
# Load function
source("../Auto_Search_Base.R")
# Load function
source("./Auto_Search_Base.R")
Sys.time()
typeof(t)
s1 = "abc"
s2 = "def"
s1 + s2
paste(s1,s2)
paste(t,s2)
t
as.Date(t)
strptime(t,format='%d/%b/%Y:%H:%M:%S')
as.POSIXlt(t)
# Save csv
file_name = paste(query, start_time, total_duration, sep = "-")
total_duration = as.difftime(90, units = "mins")
# Save csv
file_name = paste(query, start_time, total_duration, sep = "-")
file_name
file_name = paste(file_name, ".csv", sep = "")
file_name
# Save csv
file_name = paste(query, start_time, total_duration, sep = "——")
file_name = paste(file_name, ".csv", sep = "")
file_name
# Save csv
file_name = paste(query, start_time, total_duration, sep = "--")
file_name = paste(file_name, ".csv", sep = "")
save_df(tweet_df, file_name)
file_name
# Save csv
file_name = paste(query, start_time, total_duration, sep = "_")
file_name = paste(file_name, ".csv", sep = "")
file_name
# Load function
source("./Auto_Search_Base.R")
setwd("~/Desktop/Work/Src")
read_df <- read.csv(".Data/monster_2018-09-13 16/01/19_5.csv")
read_df <- read.csv("./Data/monster_2018-09-13 16/01/19_5.csv")
read_df <- read.csv("../Data/monster_2018-09-13 16/01/19_5.csv")
read_df <- read.csv("../Data/monster_2018-09-13 16:01:19_5.csv")
View(read_df)
nrow(unique(read_df))
